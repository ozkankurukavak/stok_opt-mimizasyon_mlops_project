lightgbm:
  n_estimators:
    - 100
    - 200
    - 300
    - 500
    - 1000
  learning_rate:
    - 0.01
    - 0.05
    - 0.1
    - 0.2
  num_leaves:
    - 31
    - 63  
  max_depth:
    - 3
    - 5
    - 7
    - 9
    - 12
    - 15
  min_data_in_leaf:
    - 10
    - 20
    - 30
    - 40
    - 50  
  feature_fraction:
    - 0.5
    - 0.7
    - 0.9
  bagging_freq:
    - 1
    - 2 
  bagging_fraction:
    - 0.8
    - 0.9
  min_sum_hessian_in_leaf:
    - 10
    - 20
    - 30  
  lambda_l1:
    - 0
    - 0.01
    - 0.1
  lambda_l2:
    - 0
    - 0.01
    - 0.1
  reg_alpha:
    - 0
    - 0.01
    - 0.1
  reg_lambda:
    - 0
    - 0.01
    - 0.1
  
xgboost:
  n_estimators:
    - 100
    - 200
    - 300
    - 500
    - 1000
  max_depth:
    - 3
    - 5
    - 7
    - 9
    - 12
    - 15
  learning_rate:
    - 0.01
    - 0.05
    - 0.1
    - 0.2
  subsample:
    - 0.6
    - 0.7
    - 0.8
    - 0.9
    - 1.0
  colsample_bytree:
    - 0.6
    - 0.7
    - 0.8
    - 0.9
    - 1.0
  gamma:
    - 0
    - 0.1
    - 0.3
    - 0.5
    - 1
  reg_alpha:
    - 0
    - 0.01
    - 0.1
    - 1
    - 10
  reg_lambda:
    - 0
    - 0.01
    - 0.1
    - 1
    - 10

  svr:
    - kernel:
      - linear
      - poly
      - rbf
      - sigmoid
    - C:
      - 0.1
      - 1
      - 10
    - epsilon:
      - 0.1
      - 1
    - gamma:
      - 0.1
      - 1
      - 10
    - degree:
      - 2
      - 3

randomforest:
  n_estimators:
    - 8
    - 16
    - 32
  max_depth:
    - 3
    - 5
    - 7
    - 9
    - 12
    - 15
  min_samples_split:
    - 2
    - 5
    - 10
  min_samples_leaf:
    - 1
    - 2
  max_features:
    - 0.2
    - 0.4
    - 0.6
    - 0.8
    - 1.0
    
decisiontree:
  # DecisionTreeRegressor için uygun kriterler; 
  # Eğer sınıflandırma amaçlı kullanılacaksa (DecisionTreeClassifier) orijinal kriterleri (entropy, log_loss, gini) kullanabilirsiniz.
  criterion:
    - squared_error
    - friedman_mse
    - absolute_error