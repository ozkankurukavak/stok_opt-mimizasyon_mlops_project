{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/stok_opt-mimizasyon_mlops_project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count    Dtype  \n",
      "---  ------                   --------------    -----  \n",
      " 0   InventoryId              1048575 non-null  object \n",
      " 1   Store                    1048575 non-null  int64  \n",
      " 2   Brand                    1048575 non-null  int64  \n",
      " 3   Description_sales        1048575 non-null  object \n",
      " 4   Size_sales               1048575 non-null  object \n",
      " 5   SalesQuantity            1048575 non-null  int64  \n",
      " 6   SalesDollars             1048575 non-null  float64\n",
      " 7   SalesPrice               1048575 non-null  float64\n",
      " 8   SalesDate                1048575 non-null  object \n",
      " 9   Volume_sales             1048575 non-null  int64  \n",
      " 10  Classification_sales     1048575 non-null  int64  \n",
      " 11  ExciseTax                1048575 non-null  float64\n",
      " 12  VendorNo                 1048575 non-null  int64  \n",
      " 13  VendorName_sales         1048575 non-null  object \n",
      " 14  Description_purchase     1048575 non-null  object \n",
      " 15  Price                    1048575 non-null  float64\n",
      " 16  Size_purchase            1048575 non-null  object \n",
      " 17  Volume_purchase          1048575 non-null  int64  \n",
      " 18  Classification_purchase  1048575 non-null  int64  \n",
      " 19  PurchasePrice            1048575 non-null  float64\n",
      " 20  VendorNumber             1048575 non-null  int64  \n",
      " 21  VendorName_purchase      1048575 non-null  object \n",
      "dtypes: float64(5), int64(9), object(8)\n",
      "memory usage: 176.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"artifacts/data_ingestion/satslar.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['InventoryId', 'Store', 'Brand', 'Description_sales', 'Size_sales',\n",
       "       'SalesQuantity', 'SalesDollars', 'SalesPrice', 'SalesDate',\n",
       "       'Volume_sales', 'Classification_sales', 'ExciseTax', 'VendorNo',\n",
       "       'VendorName_sales', 'Description_purchase', 'Price', 'Size_purchase',\n",
       "       'Volume_purchase', 'Classification_purchase', 'PurchasePrice',\n",
       "       'VendorNumber', 'VendorName_purchase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTİTİY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    unzip_data_dir: Path\n",
    "    all_schema: dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFİG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.stok_optimizasyonu_ml_project.constants import CONFIG_FILE_PATH,PARAMS_FILE_PATH,SCHEMA_FILE_PATH\n",
    "from src.stok_optimizasyonu_ml_project.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath= PARAMS_FILE_PATH, schema_filepath= SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            STATUS_FILE= config.STATUS_FILE,\n",
    "            unzip_data_dir = config.unzip_data_dir,\n",
    "            all_schema = schema\n",
    "        )\n",
    "\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPONENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.stok_optimizasyonu_ml_project import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def validate_all_columns(self) -> bool:\n",
    "        try:\n",
    "            validation_status = True  # Başlangıçta doğrulama başarılı (True)\n",
    "            \n",
    "            # Veriyi okuyoruz\n",
    "            data = pd.read_csv(self.config.unzip_data_dir)\n",
    "            all_cols = list(data.columns)  # Kolon isimlerini alıyoruz\n",
    "            all_schema = self.config.all_schema.keys()  # Şemadaki kolon isimleri\n",
    "            \n",
    "            # Kolonları kontrol et\n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False  # Kolon eksikse False dönecek\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}, Error: Missing Column - {col}\")\n",
    "                    return validation_status  # Eğer bir kolon eksikse işlemi sonlandırıyoruz\n",
    "\n",
    "            # Kolon sırasını kontrol et (Eğer gereksinim varsa)\n",
    "            expected_columns = list(self.config.all_schema.keys())\n",
    "            if all_cols != expected_columns:\n",
    "                validation_status = False\n",
    "                with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                    f.write(f\"Validation status: {validation_status}, Error: Column Order mismatch.\")\n",
    "\n",
    "            # Eksik veri kontrolü\n",
    "            missing_data = data.isnull().sum()  # Her kolondaki eksik veri sayısını alıyoruz\n",
    "            if missing_data.any():  # Eğer eksik veri varsa\n",
    "                validation_status = False\n",
    "                with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                    f.write(f\"Validation status: {validation_status}, Missing Data: {missing_data}\")\n",
    "            \n",
    "            # Aykırı Değer Analizi (Outlier Analysis)\n",
    "            outlier_data = self.outlier_analysis(data, threshold=1.5)  # Aykırı değer analizi\n",
    "            if outlier_data:\n",
    "                validation_status = False\n",
    "                with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                    f.write(f\"Validation status: {validation_status}, Outliers found: {outlier_data}\")\n",
    "\n",
    "            # Z-Score Aykırı Değer Analizi\n",
    "            outliers_dict = self.zscore_analysis_multi(data, columns=all_cols, threshold=3)  # Z-score ile aykırı değer analizi\n",
    "            if outliers_dict:\n",
    "                validation_status = False\n",
    "                with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                    f.write(f\"Validation status: {validation_status}, Z-score outliers: {outliers_dict}\")\n",
    "\n",
    "            # Validation durumu yazıyoruz\n",
    "            with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                f.write(f\"Validation status: {validation_status}\")\n",
    "            \n",
    "            return validation_status  # Sonuç döndürülüyor\n",
    "        except Exception as e:\n",
    "            raise e  # Hata durumunda istisna fırlatılır\n",
    "\n",
    "    # Aykırı değer tespiti (IQR - Interquartile Range) ile\n",
    "    def outlier_analysis(self, df, threshold=1.5):\n",
    "        outlier_data = {}\n",
    "        numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()  # Sayısal kolonları seçiyoruz\n",
    "\n",
    "        for column in numerical_columns:\n",
    "            Q1 = df[column].quantile(0.25)  # 1st quartile (Q1)\n",
    "            Q3 = df[column].quantile(0.75)  # 3rd quartile (Q3)\n",
    "            IQR = Q3 - Q1  # Interquartile Range (IQR)\n",
    "\n",
    "            lower_limit = Q1 - threshold * IQR  # Alt sınır\n",
    "            upper_limit = Q3 + threshold * IQR  # Üst sınır\n",
    "\n",
    "            # Aykırı değerleri tespit ediyoruz\n",
    "            outlier_mask = (df[column] < lower_limit) | (df[column] > upper_limit)\n",
    "            outlier_data[column] = {\n",
    "                \"lower_limit\": lower_limit,\n",
    "                \"upper_limit\": upper_limit,\n",
    "                \"outlier_count\": outlier_mask.sum(),  # Aykırı değerlerin sayısı\n",
    "                \"percentage\": round((outlier_mask.sum() / len(df)) * 100, 2)  # Yüzde oranı\n",
    "            }\n",
    "\n",
    "        return outlier_data  # Aykırı değerleri döndürüyoruz\n",
    "\n",
    "    # Z-score ile aykırı değer analizi (Sayısal kolonlar için)\n",
    "    def zscore_analysis_multi(self, df, columns, threshold=3):\n",
    "        outliers_dict = {}\n",
    "\n",
    "        for column in columns:\n",
    "            df[f'{column}_zscore'] = zscore(df[column])  # Z-score hesaplama\n",
    "\n",
    "            # Z-score değeri belirli bir eşik değerini aşarsa aykırı değer olarak işaretliyoruz\n",
    "            outlier_mask = (df[f'{column}_zscore'] > threshold) | (df[f'{column}_zscore'] < -threshold)\n",
    "\n",
    "            outliers_dict[column] = df[outlier_mask]  # Aykırı değerleri kaydediyoruz\n",
    "\n",
    "        return outliers_dict  # Aykırı değerlerin bulunduğu dictionary döndürülüyor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PİPELİNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValidation(config=data_validation_config)\n",
    "    \n",
    "    # Veri doğrulamasını yapıyoruz\n",
    "    validation_status = data_validation.validate_all_columns()\n",
    "    \n",
    "    if not validation_status:\n",
    "        # Validation başarısızsa, log kaydı ekleyebiliriz\n",
    "        with open(data_validation.config.STATUS_FILE, 'a') as f:  # Burada 'self' yerine 'data_validation.config' kullanıyoruz\n",
    "            f.write(f\"Data validation failed at {pd.to_datetime('now')}\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # Hata mesajını dosyaya yazabiliriz\n",
    "    with open(data_validation.config.STATUS_FILE, 'a') as f:  # Burada da aynı şekilde 'self' yerine 'data_validation.config' kullanıyoruz\n",
    "        f.write(f\"Error occurred: {str(e)}\\n\")\n",
    "    raise  # Hata tekrar raise ediliyor, böylece program daha üst seviyede yakalanabilir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
